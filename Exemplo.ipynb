{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292a924f",
   "metadata": {},
   "source": [
    "# Simulação para a apresentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f3ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6c4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model(modelName):\n",
    "    with open('modelos/' + modelName, 'rb') as pickle_file:\n",
    "        content = pickle.load(pickle_file)\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68481b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando modelos\n",
    "svm_small_gp = read_model('model_small_gp.pkl')\n",
    "svm_md_gp = read_model('model_medium_gp.pkl')\n",
    "svm_lg_gp = read_model('model_large_gp.pkl')\n",
    "cluster_model = read_model('cluster_model.pkl')\n",
    "se = read_model('standardScaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b724bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Variáveis Utilizadas em cada modelo\n",
    "gp_medium_features = [\n",
    "    'limiteEmpresaAnaliseCredito',\n",
    "    'titulosEmAberto',\n",
    "    'maiorAtraso',\n",
    "    'percentualProtestos',\n",
    "    'valorSolicitado',\n",
    "    'valorAprovado',\n",
    "]\n",
    "\n",
    "gp_large_features = [\n",
    "    'limiteEmpresaAnaliseCredito',\n",
    "    'valorAprovado',\n",
    "    'duplicatasAReceber',\n",
    "    'titulosEmAberto',\n",
    "    'valorSolicitado'\n",
    "]\n",
    "\n",
    "gp_small_features = [\n",
    "    'faturamentoBruto',\n",
    "    'periodoDemonstrativoEmMeses',\n",
    "    'limiteEmpresaAnaliseCredito',\n",
    "    'titulosEmAberto',\n",
    "    'valorSolicitado',\n",
    "    'valorAprovado',\n",
    "    'capitalSocial'\n",
    "]\n",
    "\n",
    "k_means_features = [\n",
    " 'margemBrutaAcumulada',\n",
    " 'faturamentoBruto',\n",
    " 'margemBruta',\n",
    " 'percentualRisco',\n",
    " 'percentualRisco',\n",
    " 'intervaloFundacao'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4b3c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_with_many_nulls(df):\n",
    "    '''\n",
    "    Colunas com mais de 40% de dados faltantes = drop\n",
    "    df -> dataframe para ser ajustado\n",
    "    '''\n",
    "    percentage_of_nulls = df.isnull().sum() / df.shape[0]\n",
    "    columns_to_drop = np.array(percentage_of_nulls[percentage_of_nulls > .4].index)\n",
    "    adjusted_dataframe = df.drop(columns_to_drop, axis=1)\n",
    "    return adjusted_dataframe\n",
    "\n",
    "def initial_column_selection(df):\n",
    "    '''\n",
    "    ``Helper function``\n",
    "    Dropa colunas que não serão utilizadas\n",
    "    '''\n",
    "    adjusted_df = drop_columns_with_many_nulls(df)\n",
    "    \n",
    "    ## Também não quero utilizar datas na minha regressão\n",
    "    unused_columns = ['primeiraCompra']\n",
    "    \n",
    "    # Também não quero colunas que identifiquem o cliente, quero trata-los como um ponto único\n",
    "    unused_columns = np.concatenate(\n",
    "        (\n",
    "            unused_columns, \n",
    "            np.array(['numero_solicitacao', 'cnpjSemTraco', 'nomeFantasia', 'razaoSocial', 'status'])\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return adjusted_df.drop(unused_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a976432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def predict_group(model, df, normalizer, features_used=k_means_features):\n",
    "    mapped_group_names = {0: 'medio', 1: 'pequeno', 2: 'grande'}\n",
    "    initial_sample = df.sample(1).copy()\n",
    "    test_sample = initial_sample[features_used].copy()\n",
    "    \n",
    "    total_nulls = test_sample.isnull().sum(axis=1).values[0]\n",
    "    \n",
    "    while total_nulls != 0:\n",
    "        test_sample = test_sample.sample(1).copy()\n",
    "        total_nulls = test_sample.isnull().sum(axis=1).values[0]\n",
    "    \n",
    "    sample_normalized = normalizer.transform(test_sample)\n",
    "    y_pred = model.predict(sample_normalized)\n",
    "    \n",
    "    return (mapped_group_names[y_pred[0]], initial_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05eb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_value(model, sample, features_used):\n",
    "    try:\n",
    "        test_sample = sample[1][features_used].copy()\n",
    "        features = test_sample.drop('valorAprovado', axis=1)\n",
    "        y_true = test_sample['valorAprovado']\n",
    "    \n",
    "        log_test_sample = np.log(features + 1)\n",
    "        y_pred = model.predict(log_test_sample)\n",
    "\n",
    "        print(f'''\n",
    "            Valor Real: {y_true.values[0]},\n",
    "            Valor Predito: {np.exp(y_pred[0])}\n",
    "        ''')\n",
    "    except:\n",
    "        print('Contém nulos')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28062260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grupo médio\n",
      "\n",
      "            Valor Real: 2000000.0,\n",
      "            Valor Predito: 1804546.360800371\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/bootcamp-solicitacoescredito.csv')\n",
    "df['intervaloFundacao'] = df['intervaloFundacao'].map({'De 0 a 5 anos': 0, 'De 6 a 10 anos': 1, 'De 11 a 16 anos': 2, 'Acima de 17 anos': 3})\n",
    "\n",
    "sample = predict_group(cluster_model, df, se)\n",
    "\n",
    "if sample[0] == 'pequeno':\n",
    "    print('grupo pequeno')\n",
    "    predict_value(svm_small_gp, sample, gp_small_features)\n",
    "elif sample[0] == 'medio':\n",
    "    print('grupo médio')\n",
    "    predict_value(svm_md_gp, sample, gp_medium_features)\n",
    "else:\n",
    "    print('grupo Grande')\n",
    "    predict_value(svm_lg_gp, sample, gp_large_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
