{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292a924f",
   "metadata": {},
   "source": [
    "# Simulação para a apresentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f3ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6c4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model(modelName):\n",
    "    with open('modelos/' + modelName, 'rb') as pickle_file:\n",
    "        content = pickle.load(pickle_file)\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68481b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando modelos\n",
    "svm_small_gp = read_model('model_small_gp.pkl')\n",
    "svm_md_gp = read_model('model_medium_and_large_gp.pkl')\n",
    "cluster_model = read_model('cluster_model.pkl')\n",
    "se = read_model('standardScaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b724bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Variáveis Utilizadas em cada modelo\n",
    "gp_medium_features = [\n",
    "    'limiteEmpresaAnaliseCredito',\n",
    "    'titulosEmAberto',\n",
    "    'maiorAtraso',\n",
    "    'percentualProtestos',\n",
    "    'valorSolicitado',\n",
    "    'valorAprovado',\n",
    "]\n",
    "\n",
    "gp_small_features = [\n",
    "    'faturamentoBruto',\n",
    "    'periodoDemonstrativoEmMeses',\n",
    "    'limiteEmpresaAnaliseCredito',\n",
    "    'titulosEmAberto',\n",
    "    'valorSolicitado',\n",
    "    'capitalSocial',\n",
    "    'scorePontualidade'\n",
    "]\n",
    "\n",
    "k_means_features = [\n",
    "    'margemBrutaAcumulada',\n",
    "    'faturamentoBruto',\n",
    "    'margemBruta',\n",
    "    'percentualRisco',\n",
    "    'intervaloFundacao'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4b3c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_with_many_nulls(df):\n",
    "    '''\n",
    "    Colunas com mais de 40% de dados faltantes = drop\n",
    "    df -> dataframe para ser ajustado\n",
    "    '''\n",
    "    percentage_of_nulls = df.isnull().sum() / df.shape[0]\n",
    "    columns_to_drop = np.array(percentage_of_nulls[percentage_of_nulls > .4].index)\n",
    "    adjusted_dataframe = df.drop(columns_to_drop, axis=1)\n",
    "    return adjusted_dataframe\n",
    "\n",
    "def initial_column_selection(df):\n",
    "    '''\n",
    "    ``Helper function``\n",
    "    Dropa colunas que não serão utilizadas\n",
    "    '''\n",
    "    adjusted_df = drop_columns_with_many_nulls(df)\n",
    "    \n",
    "    ## Também não quero utilizar datas na minha regressão\n",
    "    unused_columns = ['primeiraCompra']\n",
    "    \n",
    "    # Também não quero colunas que identifiquem o cliente, quero trata-los como um ponto único\n",
    "    unused_columns = np.concatenate(\n",
    "        (\n",
    "            unused_columns, \n",
    "            np.array(['numero_solicitacao', 'cnpjSemTraco', 'nomeFantasia', 'razaoSocial', 'status'])\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return adjusted_df.drop(unused_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a976432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def predict_group(model, df, normalizer, features_used=k_means_features):\n",
    "    mapped_group_names = {0: 'pequeno', 1: 'medio', 2: 'grande'}\n",
    "    initial_sample = df.sample(1).copy()\n",
    "    test_sample = initial_sample[features_used].copy()\n",
    "    \n",
    "    total_nulls = test_sample.isnull().sum(axis=1).values[0]\n",
    "    \n",
    "    while total_nulls != 0:\n",
    "        test_sample = test_sample.sample(1).copy()\n",
    "        total_nulls = test_sample.isnull().sum(axis=1).values[0]\n",
    "    \n",
    "    sample_normalized = normalizer.transform(test_sample)\n",
    "    y_pred = model.predict(sample_normalized)\n",
    "    \n",
    "    return (mapped_group_names[y_pred[0]], initial_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e05eb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_value(model, sample, features_used):\n",
    "    new_df = pd.DataFrame()\n",
    "    try:\n",
    "        initial_sample = sample[1]\n",
    "        test_sample = initial_sample[features_used].copy()\n",
    "        features = test_sample.drop('valorAprovado', axis=1)\n",
    "        y_true = test_sample['valorAprovado']\n",
    "        log_test_sample = np.log(features + 1)\n",
    "        y_pred = model.predict(log_test_sample)\n",
    "\n",
    "        print(f'''\n",
    "            Valor Real: {y_true.values[0]},\n",
    "            Valor Predito: {np.exp(y_pred[0])}\n",
    "        ''')\n",
    "        return y_pred[0]\n",
    "    except:\n",
    "        print('Contém nulos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca8b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48069e9c",
   "metadata": {},
   "source": [
    "## Exemplo de predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b98ba249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bootcamp-solicitacoescredito.csv')\n",
    "df['intervaloFundacao'] = df['intervaloFundacao'].map({'De 0 a 5 anos': 0, 'De 6 a 10 anos': 1, 'De 11 a 16 anos': 2, 'Acima de 17 anos': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caab44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "28062260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medio\n",
      "\n",
      "            Valor Real: 20000.0,\n",
      "            Valor Predito: 17100.84244564374\n",
      "        \n",
      "medio\n",
      "\n",
      "            Valor Real: 60000.0,\n",
      "            Valor Predito: 36343.522315581984\n",
      "        \n",
      "medio\n",
      "\n",
      "            Valor Real: 15000.0,\n",
      "            Valor Predito: 14423.537324648034\n",
      "        \n",
      "grupo pequeno\n",
      "Contém nulos\n",
      "medio\n",
      "\n",
      "            Valor Real: 65000.0,\n",
      "            Valor Predito: 50001.000000000015\n",
      "        \n",
      "grupo pequeno\n",
      "Contém nulos\n",
      "medio\n",
      "\n",
      "            Valor Real: 40000.0,\n",
      "            Valor Predito: 43089.69920337331\n",
      "        \n",
      "medio\n",
      "\n",
      "            Valor Real: 15000.0,\n",
      "            Valor Predito: 15000.99999999999\n",
      "        \n",
      "medio\n",
      "\n",
      "            Valor Real: 20000.0,\n",
      "            Valor Predito: 20001.000000000015\n",
      "        \n",
      "medio\n",
      "\n",
      "            Valor Real: 10000.0,\n",
      "            Valor Predito: 17381.264305067503\n",
      "        \n",
      "grupo pequeno\n",
      "Contém nulos\n",
      "medio\n",
      "\n",
      "            Valor Real: 400000.0,\n",
      "            Valor Predito: 344934.82995318057\n",
      "        \n",
      "grupo pequeno\n",
      "Contém nulos\n",
      "grupo pequeno\n",
      "Contém nulos\n",
      "grupo pequeno\n",
      "Contém nulos\n",
      "grupo pequeno\n",
      "Contém nulos\n",
      "medio\n",
      "\n",
      "            Valor Real: 15000.0,\n",
      "            Valor Predito: 14423.537324648034\n",
      "        \n",
      "grupo pequeno\n",
      "Contém nulos\n",
      "medio\n",
      "\n",
      "            Valor Real: 55000.0,\n",
      "            Valor Predito: 130193.02522272084\n",
      "        \n",
      "medio\n",
      "\n",
      "            Valor Real: 300000.0,\n",
      "            Valor Predito: 282311.8124360582\n",
      "        \n",
      "medio\n",
      "\n",
      "            Valor Real: 400000.0,\n",
      "            Valor Predito: 292402.79722742154\n",
      "        \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpequeno\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrupo pequeno\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36mpredict_group\u001b[1;34m(model, df, normalizer, features_used)\u001b[0m\n\u001b[0;32m      8\u001b[0m total_nulls \u001b[38;5;241m=\u001b[39m test_sample\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m total_nulls \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     test_sample \u001b[38;5;241m=\u001b[39m \u001b[43mtest_sample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     total_nulls \u001b[38;5;241m=\u001b[39m test_sample\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m sample_normalized \u001b[38;5;241m=\u001b[39m normalizer\u001b[38;5;241m.\u001b[39mtransform(test_sample)\n",
      "File \u001b[1;32m~\\.conda\\envs\\gpu\\lib\\site-packages\\pandas\\core\\generic.py:6032\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   5926\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   5927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, deep: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   5928\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5929\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   5930\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6030\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[0;32m   6031\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6032\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6033\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py:612\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m blknos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    611\u001b[0m         res\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;241m=\u001b[39m blknos\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 612\u001b[0m         res\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blklocs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m    615\u001b[0m     res\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    sample = predict_group(cluster_model, df, se)\n",
    "    if sample[0] == 'pequeno':\n",
    "        print('grupo pequeno')\n",
    "        y_pred = predict_value(svm_small_gp, sample, gp_small_features)\n",
    "    elif sample[0] == 'medio' or sample[0] == 'grande':\n",
    "        print(sample[0])\n",
    "        y_pred = predict_value(svm_md_gp, sample, gp_medium_features)\n",
    "    sample[1]['y_pred'] = [y_pred]\n",
    "    \n",
    "    df_example = pd.concat([df_example, sample[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0493af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example.dropna(subset=['y_pred'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2560ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example.to_csv('../predict_examples.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
